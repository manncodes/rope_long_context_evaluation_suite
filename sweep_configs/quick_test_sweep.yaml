# Quick Test Sweep Configuration
# Minimal configuration for testing the sweep functionality

# Model Configuration
model:
  type: "hf_hub"
  name: "llama-3.2-1b"
  path: "unsloth/Llama-3.2-1B"
  tokenizer_path: "unsloth/Llama-3.2-1B"
  device_map: "auto"
  torch_dtype: "bfloat16"
  attn_implementation: "eager"
  max_memory_gb: 24
  max_length: 8192
  trust_remote_code: false

# RoPE Scaling Methods to Evaluate (limited for quick test)
rope_methods:
  - name: "none"
    config: {}
  - name: "linear"
    config:
      scaling_factor: 2.0
  - name: "ntk_aware"
    config:
      scaling_factor: 2.0
      alpha: 8.0

# Evaluation Configuration
evaluation:
  batch_size: 1
  max_new_tokens: 50  # Reduced for speed
  temperature: 0.0
  do_sample: false
  num_return_sequences: 1
  pad_token_id: null
  max_context_length: 8192
  gradient_checkpointing: true
  use_cache: false

# Data Configuration
data:
  cache_dir: "./cache/"
  output_dir: "./quick_sweep_results/"

# Logging Configuration
logging:
  level: "INFO"
  file: "logs/quick_sweep.log"

# Benchmark Configuration (minimal for testing)
benchmarks:
  niah:
    enabled: true
    variants: ["standard"]
    context_lengths: [2048, 4096]  # Short contexts for quick test
    max_samples: 3  # Very few samples for speed
    
  ruler:
    enabled: false  # Disabled for quick test
    categories: ["retrieval"]
    max_length: 4096
    num_samples: 2
    
  longbench:
    enabled: false  # Disabled for quick test
    path: "data/longbench"
    tasks: ["narrativeqa"]
    max_samples: 2
    
  longbench_v2:
    enabled: false  # Disabled for quick test

# RoPE Extension Configuration (will be overridden by sweep)
rope_extension:
  method: "none"

# Hardware Configuration
hardware:
  num_gpus: 1
  gpu_memory_fraction: 0.9
  cpu_threads: 8
  mixed_precision: true
  compile_model: false
# NIAH (Needle in a Haystack) Benchmark Test Configuration with LLM Judge
# Tests the official NIAH implementation with LLM-as-judge evaluation

# Model Configuration - lightweight for testing
model:
  type: "hf_hub"
  name: "llama-3.2-1b"
  path: "unsloth/Llama-3.2-1B"
  tokenizer_path: "unsloth/Llama-3.2-1B"
  device_map: "auto"
  torch_dtype: "bfloat16"
  attn_implementation: "eager"
  max_memory_gb: 24
  max_length: 4096
  trust_remote_code: false

# RoPE Methods - simple test
rope_methods:
  - name: "none"
    config: {}

# Evaluation Configuration
evaluation:
  batch_size: 1
  max_new_tokens: 30
  temperature: 0.0
  do_sample: false
  num_return_sequences: 1
  pad_token_id: null
  max_context_length: 4096
  gradient_checkpointing: true
  use_cache: false

# Data Configuration
data:
  cache_dir: "./cache/"
  output_dir: "./test_results/niah_llm_judge/"

# Logging Configuration
logging:
  level: "INFO"
  file: "logs/niah_llm_judge_test.log"

# NIAH Benchmark Configuration with LLM Judge
benchmarks:
  niah:
    enabled: true
    variants: ["standard"]
    context_lengths: [2048, 4096]  # Test different context lengths
    depth_percents: [10, 50]       # Test different insertion depths
    needle: "42"
    retrieval_question: "What is the special magic number that was hidden?"
    max_samples: 2                  # Small number for quick test
    num_tests: 2                    # Tests per context/depth combination
    evaluation_method: "llm_judge"  # Use LLM as judge for evaluation
    
  # Disable other benchmarks
  ruler:
    enabled: false
  longbench:
    enabled: false
  longbench_v2:
    enabled: false

# RoPE Extension Configuration
rope_extension:
  method: "none"

# Hardware Configuration
hardware:
  num_gpus: 1
  gpu_memory_fraction: 0.9
  cpu_threads: 8
  mixed_precision: true
  compile_model: false